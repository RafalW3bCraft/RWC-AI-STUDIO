{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b37b3ff5"
      },
      "source": [
        "# RWC-Minus-Studio\n",
        "\n",
        "RWC-Minus-Studio is a web application built with Flask that leverages Stable Diffusion models for image generation. It provides endpoints for text-to-image and image-to-image generation, as well as a simple frontend for interaction.\n",
        "\n",
        "## Setup\n",
        "\n",
        "1. **Install Dependencies:**\n",
        "   Run the following command in your Colab notebook to install the required libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d146b3d1"
      },
      "source": [
        "!pip install --quiet diffusers transformers accelerate scipy xformers torchvision torch safetensors xformers huggingface_hub Flask flask-ngrok pillow flask-cors pydrive2 requests\n",
        "\n",
        "from huggingface_hub import login\n",
        "login(token=\"xxxxx\") # hf token here"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97eff815"
      },
      "source": [
        "## ***Source Code***"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import string\n",
        "import random\n",
        "import time\n",
        "import base64\n",
        "import traceback\n",
        "from io import BytesIO\n",
        "from typing import Dict, Any\n",
        "from functools import wraps\n",
        "from threading import Semaphore\n",
        "\n",
        "from flask import Flask, request, jsonify, render_template_string\n",
        "from flask_cors import CORS\n",
        "from werkzeug.utils import secure_filename\n",
        "from PIL import Image\n",
        "import torch\n",
        "import requests\n",
        "\n",
        "from diffusers import StableDiffusionImg2ImgPipeline, StableDiffusionPipeline\n",
        "from transformers import logging as transformers_logging\n",
        "\n",
        "try:\n",
        "    from google.colab import auth as colab_auth\n",
        "except Exception:\n",
        "    colab_auth = None\n",
        "\n",
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "\n",
        "transformers_logging.set_verbosity_error()\n",
        "\n",
        "# --------------- CONFIG ---------------\n",
        "MODEL_ID = os.environ.get(\"MODEL_ID\", \"Lykon/DreamShaper\")\n",
        "HF_TOKEN = os.environ.get(\"HF_TOKEN\")  # set if required\n",
        "DEVICE = os.environ.get(\"DEVICE\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "OUTPUT_DIR = os.environ.get(\"OUTPUT_DIR\", \"/content/drive/MyDrive/Result\")\n",
        "INPUT_DIR = os.environ.get(\"INPUT_DIR\", \"/content/drive/MyDrive/InputImages\")\n",
        "META_DIR = os.environ.get(\"META_DIR\", \"/content/drive/MyDrive/ResultMeta\")\n",
        "NGROK_DOMAIN = os.environ.get(\"NGROK_DOMAIN\", \"yourmastertrainai.pagekite.me\")  # optional\n",
        "API_KEY = os.environ.get(\"API_KEY\", \"changeme_local_only\")\n",
        "ALLOWED_EXT = {'.png', '.jpg', '.jpeg', '.webp'}\n",
        "MAX_UPLOAD_BYTES = int(os.environ.get(\"MAX_UPLOAD_BYTES\", 6 * 1024 * 1024))\n",
        "MAX_CONCURRENT_INFERENCES = int(os.environ.get(\"MAX_CONCURRENT\", 1))\n",
        "inference_semaphore = Semaphore(MAX_CONCURRENT_INFERENCES)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(INPUT_DIR, exist_ok=True)\n",
        "os.makedirs(META_DIR, exist_ok=True)\n",
        "\n",
        "STYLE_PRESETS = {\n",
        "    \"fantasy\": {\"add\": \"epic fantasy portrait, ornate details\", \"neg\": \"lowres, blurry\"},\n",
        "    \"cyberpunk\": {\"add\": \"neon cyberpunk portrait\", \"neg\": \"lowres, watermark\"},\n",
        "    \"anime\": {\"add\": \"anime portrait, clean lineart\", \"neg\": \"messy lines\"},\n",
        "    \"oil-painting\": {\"add\": \"oil painting, chiaroscuro\", \"neg\": \"smudged\"},\n",
        "}\n",
        "\n",
        "# Unique Name func\n",
        "def gen_unique_name(length: int = 9) -> str:\n",
        "    chars = string.ascii_lowercase + string.digits\n",
        "    return ''.join(random.choices(chars, k=length))\n",
        "\n",
        "def batch_file_name(batch_id: str, file_id: str, role: str, ext: str) -> str:\n",
        "    return f\"{batch_id}_{file_id}_{role}{ext}\"\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "app.app_context().push()\n",
        "\n",
        "# GDrive\n",
        "gdrive = None\n",
        "try:\n",
        "    if colab_auth is not None:\n",
        "        try:\n",
        "            colab_auth.authenticate_user()\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] colab auth:\", e)\n",
        "    gauth = GoogleAuth()\n",
        "    gdrive = GoogleDrive(gauth)\n",
        "    print(\"[INFO] GoogleDrive client initialized.\")\n",
        "except Exception as e:\n",
        "    print(\"[WARN] GoogleDrive not initialized:\", e)\n",
        "    gdrive = None\n",
        "\n",
        "def upload_to_drive(local_path: str, parent_folder_id: str = None) -> Dict[str, str]:\n",
        "    if gdrive is None:\n",
        "        return {\"error\": \"drive_not_initialized\"}\n",
        "    try:\n",
        "        meta = {'title': os.path.basename(local_path)}\n",
        "        if parent_folder_id:\n",
        "            meta['parents'] = [{'id': parent_folder_id}]\n",
        "        f = gdrive.CreateFile(meta)\n",
        "        f.SetContentFile(local_path)\n",
        "        f.Upload()\n",
        "        try:\n",
        "            f.InsertPermission({'type': 'anyone', 'value': 'anyone', 'role': 'reader'})\n",
        "        except Exception:\n",
        "            pass\n",
        "        f.FetchMetadata()\n",
        "        return {\n",
        "            \"id\": f.get('id'),\n",
        "            \"webViewLink\": f.get('alternateLink'),\n",
        "            \"webContentLink\": f.get('downloadUrl') or f.get('alternateLink')\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(\"[ERROR] upload_to_drive:\", e)\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "def ensure_batch_folder(batch_id: str, drive_client) -> str:\n",
        "    if drive_client is None:\n",
        "        return None\n",
        "    try:\n",
        "        safe_id = batch_id.replace(\"'\", \"\\\\'\")\n",
        "        q = f\"title = '{safe_id}' and mimeType = 'application/vnd.google-apps.folder' and trashed = false\"\n",
        "        lst = drive_client.ListFile({'q': q}).GetList()\n",
        "        if lst:\n",
        "            return lst[0]['id']\n",
        "        fld = drive_client.CreateFile({'title': batch_id, 'mimeType': 'application/vnd.google-apps.folder'})\n",
        "        fld.Upload()\n",
        "        return fld['id']\n",
        "    except Exception as e:\n",
        "        print(\"[ERROR] ensure_batch_folder:\", e)\n",
        "        return None\n",
        "\n",
        "def allowed_file(fn: str) -> bool:\n",
        "    _, ext = os.path.splitext(fn.lower())\n",
        "    return ext in ALLOWED_EXT\n",
        "\n",
        "def save_pil(img: Image.Image, path: str):\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    img.save(path)\n",
        "\n",
        "def pil_to_base64(img: Image.Image, fmt: str='PNG') -> str:\n",
        "    buf = BytesIO()\n",
        "    img.save(buf, format=fmt)\n",
        "    buf.seek(0)\n",
        "    return f\"data:image/{fmt.lower()};base64,{base64.b64encode(buf.read()).decode('ascii')}\"\n",
        "\n",
        "# Load pipelines\n",
        "pipe = None\n",
        "text_pipe = None\n",
        "\n",
        "use_fp16 = (DEVICE == \"cuda\") and torch.cuda.is_available()\n",
        "torch_dtype = torch.float16 if use_fp16 else torch.float32\n",
        "\n",
        "print(f\"[INFO] Loading pipelines MODEL_ID={MODEL_ID} DEVICE={DEVICE} fp16={use_fp16}\")\n",
        "\n",
        "# load Img2Img\n",
        "try:\n",
        "    kwargs = {}\n",
        "    if HF_TOKEN:\n",
        "        kwargs['use_auth_token'] = HF_TOKEN\n",
        "    pipe = StableDiffusionImg2ImgPipeline.from_pretrained(MODEL_ID, torch_dtype=torch_dtype, **kwargs)\n",
        "    try:\n",
        "        pipe = pipe.to(DEVICE)\n",
        "    except Exception:\n",
        "        pipe = pipe.to('cpu')\n",
        "    try:\n",
        "        pipe.enable_xformers_memory_efficient_attention()\n",
        "    except Exception:\n",
        "        pass\n",
        "    print(\"[INFO] Img2Img pipeline loaded from\", MODEL_ID)\n",
        "except Exception as e:\n",
        "    print(\"[WARN] Img2Img load failed for\", MODEL_ID, \":\", e)\n",
        "    try:\n",
        "        fallback = \"runwayml/stable-diffusion-v1-5\"\n",
        "        print(\"[INFO] Attempting fallback Img2Img:\", fallback)\n",
        "        pipe = StableDiffusionImg2ImgPipeline.from_pretrained(fallback, torch_dtype=torch_dtype, **kwargs)\n",
        "        pipe = pipe.to(DEVICE if torch.cuda.is_available() else 'cpu')\n",
        "        print(\"[INFO] Fallback Img2Img loaded:\", fallback)\n",
        "    except Exception as e2:\n",
        "        print(\"[ERROR] Fallback Img2Img load failed:\", e2)\n",
        "        pipe = None\n",
        "\n",
        "# load text->image\n",
        "try:\n",
        "    kwargs = {}\n",
        "    if HF_TOKEN:\n",
        "        kwargs['use_auth_token'] = HF_TOKEN\n",
        "    text_pipe = StableDiffusionPipeline.from_pretrained(MODEL_ID, torch_dtype=torch_dtype, **kwargs)\n",
        "    try:\n",
        "        text_pipe = text_pipe.to(DEVICE)\n",
        "    except Exception:\n",
        "        text_pipe = text_pipe.to('cpu')\n",
        "    try:\n",
        "        text_pipe.enable_xformers_memory_efficient_attention()\n",
        "    except Exception:\n",
        "        pass\n",
        "    print(\"[INFO] text2img pipeline loaded from\", MODEL_ID)\n",
        "except Exception as e:\n",
        "    print(\"[WARN] text2img load failed for\", MODEL_ID, \":\", e)\n",
        "    try:\n",
        "        fb = \"runwayml/stable-diffusion-v1-5\"\n",
        "        kwargs = {}\n",
        "        if HF_TOKEN:\n",
        "            kwargs['use_auth_token'] = HF_TOKEN\n",
        "        text_pipe = StableDiffusionPipeline.from_pretrained(fb, torch_dtype=torch_dtype, **kwargs)\n",
        "        text_pipe = text_pipe.to(DEVICE if torch.cuda.is_available() else 'cpu')\n",
        "        print(\"[INFO] Fallback text2img loaded:\", fb)\n",
        "    except Exception as e2:\n",
        "        print(\"[WARN] fallback text2img failed:\", e2)\n",
        "        text_pipe = None\n",
        "\n",
        "def require_api_key(f):\n",
        "    @wraps(f)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        key = request.headers.get(\"X-API-KEY\") or request.args.get(\"api_key\")\n",
        "        if not key or key != API_KEY:\n",
        "            return jsonify({\"error\": \"unauthorized\"}), 401\n",
        "        return f(*args, **kwargs)\n",
        "    return wrapper\n",
        "\n",
        "def safe_int(v, default=0):\n",
        "    try:\n",
        "        return int(v)\n",
        "    except Exception:\n",
        "        return default\n",
        "\n",
        "# Endpoints\n",
        "\n",
        "@app.route('/health', methods=['GET'])\n",
        "def health():\n",
        "    return jsonify({\n",
        "        \"ok\": True,\n",
        "        \"img2img_loaded\": pipe is not None,\n",
        "        \"text2img_loaded\": text_pipe is not None,\n",
        "        \"device\": DEVICE\n",
        "    })\n",
        "\n",
        "@app.route('/generate_text', methods=['POST'])\n",
        "@require_api_key\n",
        "def generate_text():\n",
        "    if text_pipe is None:\n",
        "        return jsonify({\"error\": \"text_pipe_not_loaded\"}), 500\n",
        "    try:\n",
        "        data = request.get_json(force=True)\n",
        "    except Exception:\n",
        "        return jsonify({\"error\": \"invalid_json\"}), 400\n",
        "\n",
        "    prompt = (data.get(\"prompt\") or \"\").strip()\n",
        "    style = (data.get(\"style\") or \"\").strip().lower()\n",
        "    neg = (data.get(\"negative_prompt\") or \"\").strip()\n",
        "    if not prompt:\n",
        "        return jsonify({\"error\": \"missing_prompt\"}), 400\n",
        "\n",
        "    if style and style in STYLE_PRESETS:\n",
        "        prompt += f\", {STYLE_PRESETS[style]['add']}\"\n",
        "        if not neg:\n",
        "            neg = STYLE_PRESETS[style].get('neg', '')\n",
        "\n",
        "    steps = safe_int(data.get(\"num_inference_steps\", 128), 328)\n",
        "    guidance = float(data.get(\"guidance_scale\", 7.5))\n",
        "    batch_id = (data.get(\"batch_id\") or gen_unique_name()).lower()\n",
        "    file_id = gen_unique_name()\n",
        "    ext = \".png\"\n",
        "    out_name = batch_file_name(batch_id, file_id, \"out\", ext)\n",
        "    out_local = os.path.join(OUTPUT_DIR, out_name)\n",
        "\n",
        "    acquired = inference_semaphore.acquire(timeout=300)\n",
        "    if not acquired:\n",
        "        return jsonify({\"error\": \"inference_semaphore_timeout\"}), 500\n",
        "    try:\n",
        "        out = text_pipe(prompt=prompt, negative_prompt=neg if neg else None,\n",
        "                        num_inference_steps=steps, guidance_scale=guidance).images[0]\n",
        "        save_pil(out, out_local)\n",
        "    except Exception as e:\n",
        "        traceback.print_exc()\n",
        "        return jsonify({\"error\": f\"generation_failed: {str(e)}\"}), 500\n",
        "    finally:\n",
        "        inference_semaphore.release()\n",
        "\n",
        "    drive_links = {}\n",
        "    if gdrive is not None:\n",
        "        fid = ensure_batch_folder(batch_id, gdrive)\n",
        "        if fid:\n",
        "            drive_links = upload_to_drive(out_local, fid)\n",
        "\n",
        "    return jsonify({\n",
        "        \"batch_id\": batch_id,\n",
        "        \"file_id\": file_id,\n",
        "        \"base64\": pil_to_base64(out),\n",
        "        \"output_local\": out_local,\n",
        "        \"drive\": drive_links\n",
        "    }), 200\n",
        "\n",
        "@app.route('/generate_from_upload', methods=['POST'])\n",
        "@require_api_key\n",
        "def generate_from_upload():\n",
        "    if pipe is None:\n",
        "        return jsonify({\"error\": \"img2img_pipeline_not_loaded\"}), 500\n",
        "\n",
        "    file = request.files.get('file')\n",
        "    if not file:\n",
        "        return jsonify({\"error\": \"no_file\"}), 400\n",
        "    filename = secure_filename(file.filename or \"upload.png\")\n",
        "    if not allowed_file(filename):\n",
        "        return jsonify({\"error\": \"invalid_file_type\"}), 400\n",
        "\n",
        "    batch_id = (request.form.get(\"batch_id\") or gen_unique_name()).lower()\n",
        "    file_id = gen_unique_name()\n",
        "\n",
        "    style = (request.form.get(\"style\") or \"\").strip().lower()\n",
        "    prompt = (request.form.get(\"prompt\") or \"\").strip()\n",
        "    if style and style in STYLE_PRESETS:\n",
        "        prompt += f\", {STYLE_PRESETS[style]['add']}\"\n",
        "    neg = (request.form.get(\"negative_prompt\") or \"\").strip()\n",
        "    if not neg and style and style in STYLE_PRESETS:\n",
        "        neg = STYLE_PRESETS[style].get('neg', \"\")\n",
        "\n",
        "    try:\n",
        "        # size check\n",
        "        file.stream.seek(0, 2)\n",
        "        filesize = file.stream.tell()\n",
        "        file.stream.seek(0)\n",
        "    except Exception:\n",
        "        data = file.read()\n",
        "        filesize = len(data)\n",
        "        file.stream = BytesIO(data)\n",
        "    if filesize > MAX_UPLOAD_BYTES:\n",
        "        return jsonify({\"error\": \"file_too_large\"}), 400\n",
        "\n",
        "    ext = os.path.splitext(filename)[1].lower()\n",
        "    local_in = os.path.join(INPUT_DIR, batch_file_name(batch_id, file_id, \"in\", ext))\n",
        "    local_out = os.path.join(OUTPUT_DIR, batch_file_name(batch_id, file_id, \"out\", ext))\n",
        "\n",
        "    try:\n",
        "        img = Image.open(file.stream).convert(\"RGB\")\n",
        "        save_pil(img, local_in)\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": f\"cannot_open_uploaded_image: {e}\"}), 400\n",
        "\n",
        "    strength = float(request.form.get(\"strength\", 0.7))\n",
        "    steps = safe_int(request.form.get(\"num_inference_steps\", 342), 342)\n",
        "    guidance = float(request.form.get(\"guidance_scale\", 8.5))\n",
        "\n",
        "    acquired = inference_semaphore.acquire(timeout=300)\n",
        "    if not acquired:\n",
        "        return jsonify({\"error\": \"inference_semaphore_timeout\"}), 500\n",
        "\n",
        "    try:\n",
        "        out_img = pipe(\n",
        "            prompt=prompt,\n",
        "            image=img,\n",
        "            negative_prompt=neg if neg else None,\n",
        "            strength=strength,\n",
        "            guidance_scale=guidance,\n",
        "            num_inference_steps=steps,\n",
        "        ).images[0]\n",
        "        save_pil(out_img, local_out)\n",
        "    except Exception as e:\n",
        "        traceback.print_exc()\n",
        "        return jsonify({\"error\": f\"img2img_failed: {str(e)}\"}), 500\n",
        "    finally:\n",
        "        inference_semaphore.release()\n",
        "\n",
        "    drive_in = {}\n",
        "    drive_out = {}\n",
        "    if gdrive is not None:\n",
        "        folder_id = ensure_batch_folder(batch_id, gdrive)\n",
        "        if folder_id:\n",
        "            drive_in = upload_to_drive(local_in, folder_id)\n",
        "            drive_out = upload_to_drive(local_out, folder_id)\n",
        "\n",
        "    return jsonify({\n",
        "        \"batch_id\": batch_id,\n",
        "        \"file_id\": file_id,\n",
        "        \"input_local\": local_in,\n",
        "        \"output_local\": local_out,\n",
        "        \"input_drive\": drive_in,\n",
        "        \"output_drive\": drive_out,\n",
        "        \"base64\": pil_to_base64(out_img)\n",
        "    }), 200\n",
        "\n",
        "@app.route('/upload_for_training', methods=['POST'])\n",
        "@require_api_key\n",
        "def upload_for_training():\n",
        "    file = request.files.get('file')\n",
        "    if not file:\n",
        "        return jsonify({\"error\": \"no_file\"}), 400\n",
        "    filename = secure_filename(file.filename or \"train.png\")\n",
        "    if not allowed_file(filename):\n",
        "        return jsonify({\"error\": \"invalid_file_type\"}), 400\n",
        "\n",
        "    try:\n",
        "        file.stream.seek(0, 2)\n",
        "        filesize = file.stream.tell()\n",
        "        file.stream.seek(0)\n",
        "    except Exception:\n",
        "        data = file.read()\n",
        "        filesize = len(data)\n",
        "        file.stream = BytesIO(data)\n",
        "\n",
        "    if filesize > (10 * 1024 * 1024):\n",
        "        return jsonify({\"error\": \"file_too_large\"}), 400\n",
        "\n",
        "    label = (request.form.get(\"label\") or \"unlabeled\").strip()\n",
        "    folder = os.path.join(META_DIR, \"training_samples\", secure_filename(label))\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    ts = int(time.time())\n",
        "    unique = gen_unique_name()\n",
        "    local = os.path.join(folder, f\"{ts}_{unique}_{filename}\")\n",
        "    try:\n",
        "        img = Image.open(file.stream).convert(\"RGB\")\n",
        "        save_pil(img, local)\n",
        "        return jsonify({\"status\": \"ok\", \"local_path\": local}), 200\n",
        "    except Exception as e:\n",
        "        traceback.print_exc()\n",
        "        return jsonify({\"error\": f\"save_failed: {str(e)}\"}), 500\n",
        "\n",
        "# Minimum Frontend\n",
        "HTML = \"\"\"\n",
        "<!doctype html>\n",
        "<html>\n",
        "<head>\n",
        "<meta charset=\"utf-8\">\n",
        "<title>RWC-Minus-Studio</title>\n",
        "<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\">\n",
        "<style>\n",
        "  body {\n",
        "    font-family: \"Share Tech Mono\", monospace, system-ui;\n",
        "    background: #0a0a0f;\n",
        "    margin: 20px;\n",
        "    color: #e0e0e0;\n",
        "  }\n",
        "  h2 {\n",
        "    color: #00ffe7;\n",
        "    text-shadow: 0 0 6px #00ffe7, 0 0 12px #008080;\n",
        "    letter-spacing: 1px;\n",
        "  }\n",
        "  label {\n",
        "    display: block;\n",
        "    margin-top: 10px;\n",
        "    color: #a0f0ff;\n",
        "    font-size: 14px;\n",
        "  }\n",
        "  input, button, select, textarea {\n",
        "    font-family: inherit;\n",
        "    font-size: 14px;\n",
        "    padding: 8px;\n",
        "    border-radius: 6px;\n",
        "    border: 1px solid #333;\n",
        "    background: #111;\n",
        "    color: #eee;\n",
        "    outline: none;\n",
        "    margin-top: 4px;\n",
        "  }\n",
        "  select, textarea {\n",
        "    width: 100%;\n",
        "  }\n",
        "  button {\n",
        "    cursor: pointer;\n",
        "    background: linear-gradient(90deg, #00ffe7, #0066ff);\n",
        "    border: none;\n",
        "    color: black;\n",
        "    font-weight: bold;\n",
        "    transition: all 0.2s ease;\n",
        "  }\n",
        "  button:hover {\n",
        "    transform: scale(1.05);\n",
        "    box-shadow: 0 0 12px #00ffe7;\n",
        "  }\n",
        "  .preview img {\n",
        "    max-width: 640px;\n",
        "    border: 2px solid #00ffe7;\n",
        "    border-radius: 10px;\n",
        "    margin-top: 12px;\n",
        "    box-shadow: 0 0 10px #00ffe7;\n",
        "  }\n",
        "  .muted {\n",
        "    color: #888;\n",
        "    font-size: 13px;\n",
        "    margin-top: 8px;\n",
        "  }\n",
        "</style>\n",
        "<link href=\"https://fonts.googleapis.com/css2?family=Share+Tech+Mono&display=swap\" rel=\"stylesheet\">\n",
        "</head>\n",
        "<body>\n",
        "<h2>RWC-Minus-Studio</h2>\n",
        "<div>\n",
        "  <label>Mode:\n",
        "    <select id=\"mode\">\n",
        "      <option value=\"text\">Text → Image</option>\n",
        "      <option value=\"edit\">Image → Image (Edit)</option>\n",
        "      <option value=\"enhance\">Enhance</option>\n",
        "    </select>\n",
        "  </label>\n",
        "\n",
        "  <label>Image (for edit/enhance / training):\n",
        "    <input id=\"file\" type=\"file\" accept=\"image/*\">\n",
        "  </label>\n",
        "\n",
        "  <label>Prompt:</label>\n",
        "  <textarea id=\"prompt\" rows=\"3\" placeholder=\"Enter prompt (for text→image or edit)\"></textarea>\n",
        "\n",
        "  <label>Style:\n",
        "    <select id=\"style\">\n",
        "      <option value=\"\">(none)</option>\n",
        "      <option value=\"fantasy\">fantasy</option>\n",
        "      <option value=\"cyberpunk\">cyberpunk</option>\n",
        "      <option value=\"anime\">anime</option>\n",
        "      <option value=\"oil-painting\">oil-painting</option>\n",
        "    </select>\n",
        "  </label>\n",
        "\n",
        "  <div style=\"margin-top:12px;\">\n",
        "    <button onclick=\"generate()\">Generate</button>\n",
        "    <button onclick=\"uploadTraining()\">Upload for training</button>\n",
        "  </div>\n",
        "</div>\n",
        "\n",
        "<div id=\"status\" class=\"muted\"></div>\n",
        "<div class=\"preview\" id=\"preview\"></div>\n",
        "\n",
        "<script>\n",
        "const API_KEY = 'changeme_local_only'; // change before deploy\n",
        "\n",
        "async function generate(){\n",
        "  const mode = document.getElementById('mode').value;\n",
        "  const fileInput = document.getElementById('file');\n",
        "  const prompt = document.getElementById('prompt').value.trim();\n",
        "  const style = document.getElementById('style').value;\n",
        "  const status = document.getElementById('status');\n",
        "  const preview = document.getElementById('preview');\n",
        "  status.textContent = '⚡ Processing...';\n",
        "  preview.innerHTML = '';\n",
        "  try{\n",
        "    if(mode === 'text'){\n",
        "      const res = await fetch('/generate_text', {\n",
        "        method:'POST',\n",
        "        headers:{'Content-Type':'application/json','X-API-KEY':API_KEY},\n",
        "        body: JSON.stringify({prompt, style})\n",
        "      });\n",
        "      const data = await res.json();\n",
        "      if(!res.ok){ status.textContent = '❌ Failed: ' + (data.error||res.statusText); return; }\n",
        "      preview.innerHTML = '<div><img src=\"'+data.base64+'\"></div>';\n",
        "      status.textContent = '✅ Done (text→image) | batch:'+data.batch_id+' id:'+data.file_id;\n",
        "    } else {\n",
        "      if(!fileInput.files || !fileInput.files[0]){ status.textContent='⚠️ Select an image for edit/enhance'; return; }\n",
        "      const fd = new FormData();\n",
        "      fd.append('file', fileInput.files[0]);\n",
        "      fd.append('prompt', prompt);\n",
        "      fd.append('mode', mode);\n",
        "      fd.append('style', style);\n",
        "      const res = await fetch('/generate_from_upload', {method:'POST', headers:{'X-API-KEY':API_KEY}, body: fd});\n",
        "      const data = await res.json();\n",
        "      if(!res.ok){ status.textContent = '❌ Failed: ' + (data.error||res.statusText); return; }\n",
        "      preview.innerHTML = '<div><img src=\"'+data.base64+'\"></div>';\n",
        "      status.textContent = '✅ Done (image→image) | batch:'+data.batch_id+' id:'+data.file_id;\n",
        "    }\n",
        "  } catch(e){\n",
        "    console.error(e);\n",
        "    status.textContent = '🔥 Error: ' + e.message;\n",
        "  }\n",
        "}\n",
        "\n",
        "async function uploadTraining(){\n",
        "  const fileInput = document.getElementById('file');\n",
        "  const status = document.getElementById('status');\n",
        "  if(!fileInput.files || !fileInput.files[0]){ status.textContent='⚠️ Select an image to upload for training'; return; }\n",
        "  const fd = new FormData();\n",
        "  fd.append('file', fileInput.files[0]);\n",
        "  fd.append('label','user_upload');\n",
        "  status.textContent = '⏫ Uploading for training...';\n",
        "  try{\n",
        "    const res = await fetch('/upload_for_training', {method:'POST', headers:{'X-API-KEY':API_KEY}, body:fd});\n",
        "    const data = await res.json();\n",
        "    if(!res.ok){ status.textContent = '❌ Upload failed: '+(data.error||res.statusText); return; }\n",
        "    status.textContent = '✅ Uploaded for training: ' + data.local_path;\n",
        "  } catch(e){\n",
        "    console.error(e);\n",
        "    status.textContent = '🔥 Error: ' + e.message;\n",
        "  }\n",
        "}\n",
        "</script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template_string(HTML)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        if NGROK_DOMAIN:\n",
        "            try:\n",
        "                os.system(f\"ngrok http 80 --domain={NGROK_DOMAIN} &\")\n",
        "                print(\"[INFO] started ngrok with domain:\", NGROK_DOMAIN)\n",
        "            except Exception as e:\n",
        "                print(\"[WARN] ngrok start failed:\", e)\n",
        "        print(\"[INFO] Starting Flask on 0.0.0.0:80\")\n",
        "        app.run(host='0.0.0.0', port=80)\n",
        "    finally:\n",
        "        pass"
      ],
      "metadata": {
        "id": "yLNAoCbaBpOf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}